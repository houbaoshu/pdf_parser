#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GEA RAGç³»ç»Ÿ - Streamlit Webç•Œé¢
æä¾›å‹å¥½çš„Webäº¤äº’ç•Œé¢è¿›è¡Œé—®ç­”
"""

import os
import streamlit as st
from datetime import datetime
from typing import List, Dict, Any

from gea_rag_agent_openai import GEARAGAgent, RAGAnswer


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="GEA RAG æ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: 800;
        background: linear-gradient(90deg, #1f77b4, #00d2ff);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        padding: 1.5rem 0;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.1rem;
        color: #555;
        text-align: center;
        margin-top: -1.5rem;
        margin-bottom: 2rem;
        font-style: italic;
    }
    .source-box {
        background: rgba(255, 255, 255, 0.7);
        backdrop-filter: blur(10px);
        border-right: 1px solid rgba(255, 255, 255, 0.3);
        border-bottom: 1px solid rgba(255, 255, 255, 0.3);
        border-left: 5px solid #1f77b4;
        padding: 1.2rem;
        margin: 1rem 0;
        border-radius: 0.8rem;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
        transition: transform 0.2s ease;
    }
    .source-box:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 12px rgba(0,0,0,0.1);
    }
    .similarity-high {
        background-color: #d4edda;
        color: #155724;
        padding: 0.2rem 0.5rem;
        border-radius: 0.3rem;
        font-weight: 600;
    }
    .similarity-medium {
        background-color: #fff3cd;
        color: #856404;
        padding: 0.2rem 0.5rem;
        border-radius: 0.3rem;
        font-weight: 600;
    }
    .similarity-low {
        background-color: #f8d7da;
        color: #721c24;
        padding: 0.2rem 0.5rem;
        border-radius: 0.3rem;
        font-weight: 600;
    }
    .stat-box {
        background: linear-gradient(135deg, #e8f4f8 0%, #d1e9f0 100%);
        padding: 1.2rem;
        border-radius: 1rem;
        margin: 0.8rem 0;
        border: 1px solid rgba(31, 119, 180, 0.2);
    }
    .stChatMessage {
        border-radius: 1.5rem;
        padding: 1rem;
        margin-bottom: 1rem;
    }
    .stExpander {
        border: none !important;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        border-radius: 0.8rem !important;
    }
</style>
""", unsafe_allow_html=True)


@st.cache_resource
def initialize_agent():
    """åˆå§‹åŒ–RAG Agentï¼ˆç¼“å­˜ï¼‰"""
    agent = GEARAGAgent(model="gpt-4o-mini")
    if agent.initialize():
        return agent
    return None


def get_similarity_class(similarity: float) -> str:
    """æ ¹æ®ç›¸ä¼¼åº¦è¿”å›CSSç±»å"""
    if similarity >= 0.6:
        return "similarity-high"
    elif similarity >= 0.4:
        return "similarity-medium"
    else:
        return "similarity-low"


def format_source(source: Dict[str, Any], index: int) -> str:
    """æ ¼å¼åŒ–æ¥æºæ–‡æ¡£"""
    sim_class = get_similarity_class(source['similarity'])

    html = f"""
    <div class="source-box">
        <strong>ğŸ“„ æ¥æº {index}</strong><br>
        <strong>æ–‡ä»¶:</strong> {os.path.basename(source['source_file'])}<br>
        <strong>é¡µç :</strong> {source['page']} |
        <strong>ç±»å‹:</strong> {source['type']} |
        <strong>ç›¸ä¼¼åº¦:</strong> <span class="{sim_class}">{source['similarity']:.3f}</span><br>
        <strong>å†…å®¹é¢„è§ˆ:</strong> {source['content_preview']}
    </div>
    """
    return html


def display_message(role: str, content: str, answer: RAGAnswer = None):
    """æ˜¾ç¤ºæ¶ˆæ¯"""
    if role == "user":
        with st.chat_message("user"):
            st.markdown(content)
    else:
        with st.chat_message("assistant"):
            st.markdown(content)

            # å¦‚æœæœ‰å®Œæ•´ç­”æ¡ˆå¯¹è±¡ï¼Œæ˜¾ç¤ºé¢å¤–ä¿¡æ¯
            if answer and answer.has_answer:
                # æ˜¾ç¤ºæ¥æº
                with st.expander(f"ğŸ“š æŸ¥çœ‹æ¥æºæ–‡æ¡£ ({len(answer.sources)}ä¸ª)", expanded=False):
                    for i, source in enumerate(answer.sources, 1):
                        st.markdown(format_source(source, i), unsafe_allow_html=True)

                # æ˜¾ç¤ºtokensä½¿ç”¨
                if answer.tokens_used:
                    cost = (answer.tokens_used / 1_000_000) * 0.75
                    st.caption(f"ğŸ’° Tokens: {answer.tokens_used} (~${cost:.4f})")


def main():
    """ä¸»å‡½æ•°"""
    # æ ‡é¢˜
    st.markdown('<div class="main-header">ğŸ¤– GEA RAG æ™ºèƒ½é—®ç­”ç³»ç»Ÿ</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">åŸºäº Chroma å‘é‡æ£€ç´¢ + OpenAI GPT-4o-mini</div>', unsafe_allow_html=True)

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'messages' not in st.session_state:
        st.session_state.messages = []

    if 'agent' not in st.session_state:
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–RAG Agent..."):
            agent = initialize_agent()
            if agent is None:
                st.error("âŒ åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç¯å¢ƒå˜é‡ï¼ˆOPENAI_API_KEYï¼‰")
                st.stop()
            st.session_state.agent = agent
            st.success("âœ… RAG Agentåˆå§‹åŒ–æˆåŠŸï¼")

    agent = st.session_state.agent

    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®é€‰é¡¹")
        
        # APIè®¾ç½®
        with st.expander("ğŸ”‘ API è®¾ç½®", expanded=False):
            api_key = st.text_input("OpenAI API Key", type="password", value=os.getenv("OPENAI_API_KEY", ""))
            if api_key:
                os.environ["OPENAI_API_KEY"] = api_key
                # å¦‚æœAgentå·²ç»åˆå§‹åŒ–ä½†Keyå˜äº†ï¼Œé‡æ–°åˆå§‹åŒ–
                if 'agent' in st.session_state and st.session_state.agent.client.api_key != api_key:
                    st.session_state.agent = None
                    st.rerun()

        # æ£€ç´¢é…ç½®
        st.subheader("æ£€ç´¢è®¾ç½®")
        top_k = st.slider("æ£€ç´¢æ–‡æ¡£æ•°é‡ (top_k)", min_value=1, max_value=10, value=5, step=1)

        chunk_type = st.selectbox(
            "æ–‡æ¡£ç±»å‹è¿‡æ»¤",
            options=["å…¨éƒ¨", "æ–‡æœ¬", "è¡¨æ ¼", "å›¾åƒ"],
            index=0
        )
        chunk_types = None
        if chunk_type == "æ–‡æœ¬":
            chunk_types = ["text"]
        elif chunk_type == "è¡¨æ ¼":
            chunk_types = ["table"]
        elif chunk_type == "å›¾åƒ":
            chunk_types = ["image"]

        # ç”Ÿæˆé…ç½®
        st.subheader("ç”Ÿæˆè®¾ç½®")
        temperature = st.slider(
            "ç”Ÿæˆæ¸©åº¦ (temperature)",
            min_value=0.0,
            max_value=1.0,
            value=0.7,
            step=0.1,
            help="è¾ƒä½çš„å€¼æ›´ç²¾ç¡®ï¼Œè¾ƒé«˜çš„å€¼æ›´æœ‰åˆ›æ„"
        )

        max_tokens = st.slider(
            "æœ€å¤§ç”ŸæˆTokens",
            min_value=100,
            max_value=2000,
            value=1000,
            step=100
        )

        st.divider()

        # ç³»ç»Ÿç»Ÿè®¡
        st.subheader("ğŸ“Š ç³»ç»Ÿç»Ÿè®¡")
        if hasattr(agent, 'qa_agent'):
            stats = agent.qa_agent.retriever.get_statistics()

            st.markdown(f"""
            <div class="stat-box">
            <strong>æ€»æ–‡æ¡£æ•°:</strong> {stats.get('total_chunks', 0)}<br>
            <strong>æ–‡æœ¬:</strong> {stats.get('type_distribution', {}).get('text', 0)}<br>
            <strong>è¡¨æ ¼:</strong> {stats.get('type_distribution', {}).get('table', 0)}<br>
            <strong>å›¾åƒ:</strong> {stats.get('type_distribution', {}).get('image', 0)}
            </div>
            """, unsafe_allow_html=True)

        st.divider()

        # æ“ä½œæŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", use_container_width=True):
            st.session_state.messages = []
            st.rerun()

        # å¸®åŠ©ä¿¡æ¯
        with st.expander("ğŸ’¡ æé—®æŠ€å·§"):
            st.markdown("""
            **å¥½çš„é—®é¢˜ç¤ºä¾‹:**
            - TPS 2030çš„è½¬é€Ÿæ˜¯å¤šå°‘ï¼Ÿ
            - å¦‚ä½•æ›´æ¢æœºæ¢°å¯†å°ï¼Ÿ
            - è®¾å¤‡ç»´æŠ¤éœ€è¦æ³¨æ„å“ªäº›å®‰å…¨äº‹é¡¹ï¼Ÿ

            **é¿å…:**
            - å¤ªæ¨¡ç³Šçš„é—®é¢˜ï¼ˆ"æ€ä¹ˆæ ·ï¼Ÿ"ï¼‰
            - æ–‡æ¡£ä¸­æ²¡æœ‰çš„å†…å®¹ï¼ˆ"ä»·æ ¼å¤šå°‘ï¼Ÿ"ï¼‰
            """)

    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for msg in st.session_state.messages:
        display_message(
            msg["role"],
            msg["content"],
            msg.get("answer")  # å®Œæ•´ç­”æ¡ˆå¯¹è±¡ï¼ˆå¦‚æœæœ‰ï¼‰
        )

    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({
            "role": "user",
            "content": prompt
        })
        display_message("user", prompt)

        # ç”Ÿæˆå›ç­”
        with st.spinner("ğŸ¤” æ­£åœ¨æ€è€ƒ..."):
            try:
                answer = agent.query(
                    question=prompt,
                    top_k=top_k,
                    chunk_types=chunk_types,
                    temperature=temperature,
                    max_tokens=max_tokens
                )

                # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": answer.answer,
                    "answer": answer  # ä¿å­˜å®Œæ•´ç­”æ¡ˆå¯¹è±¡
                })

                # æ˜¾ç¤ºå›ç­”
                display_message("assistant", answer.answer, answer)

            except Exception as e:
                error_msg = f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": error_msg
                })

    # é¡µè„š
    st.divider()
    col1, col2, col3 = st.columns(3)
    with col1:
        st.caption("ğŸ” å‘é‡æ£€ç´¢: Chroma")
    with col2:
        st.caption("ğŸ§  Embedding: BGE-base-zh-v1.5")
    with col3:
        st.caption("ğŸ’¬ LLM: GPT-4o-mini")


if __name__ == "__main__":
    main()
